{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (1.2.5)\n",
      "Requirement already satisfied: six in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: plotly in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from plotly->catboost) (8.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages (from xgboost) (1.9.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 13:42:07.473702: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 13:42:07.543972: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-17 13:42:07.544018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-17 13:42:07.546522: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-17 13:42:07.559501: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 13:42:07.560882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 13:42:09.169516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ file data.pkl.File nay chua du lieu da duoc can bang voi WGAN va ENN-Kmean\n",
    "with open('cse-cic-ids2018-balanced.pkl', 'rb') as file:\n",
    "    data_loaded = pickle.load(file)\n",
    "\n",
    "X_train = data_loaded['X_train']\n",
    "X_test = data_loaded['X_test']\n",
    "y_train = data_loaded['y_train']\n",
    "y_test = data_loaded['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 7000\n",
      "1: 7000\n",
      "2: 7000\n",
      "3: 7000\n",
      "4: 7000\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Hiển thị các giá trị và tần suất xuất hiện tương ứng\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f'{value}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: 183\n",
      "1.0: 69\n",
      "2.0: 519\n",
      "3.0: 3000\n",
      "4.0: 3000\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Hiển thị các giá trị và tần suất xuất hiện tương ứng\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f'{value}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22074038e-03, 3.52941176e-01, 9.58525925e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 6.75264732e-05, 2.37231481e-05, 9.15580385e-03,\n",
       "        0.00000000e+00, 8.92354041e-03, 1.60312297e-02, 2.44460857e-01,\n",
       "        0.00000000e+00, 1.13516227e-01, 2.48991856e-01, 8.38257082e-08,\n",
       "        1.69711126e-07, 1.36941931e-02, 3.36699180e-02, 5.41503253e-02,\n",
       "        3.33356879e-08, 5.41590289e-02, 1.80542697e-02, 4.44513841e-02,\n",
       "        5.41529833e-02, 2.23349109e-06, 9.58527168e-02, 3.19740151e-02,\n",
       "        4.02641956e-02, 5.41857564e-02, 9.84880040e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 8.40103992e-08, 1.73878086e-07, 0.00000000e+00,\n",
       "        1.02731223e-02, 4.18128565e-02, 2.61466251e-02, 6.83646002e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 4.70210167e-02, 8.92354041e-03, 1.13516227e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 6.75264732e-05,\n",
       "        2.08539701e-04, 2.37231481e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 1.05810791e-05, 0.00000000e+00,\n",
       "        1.05810791e-05, 1.05810791e-05, 5.41503332e-02, 0.00000000e+00,\n",
       "        5.41503332e-02, 5.41503332e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 4.23367170e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 3.53655597e-05, 3.48321752e-05, 4.79515829e-03,\n",
       "        0.00000000e+00, 4.67351523e-03, 8.39601690e-03, 3.58936484e-01,\n",
       "        0.00000000e+00, 1.66673373e-01, 3.65589251e-01, 1.94181866e-07,\n",
       "        3.89502288e-07, 6.04852804e-03, 2.23706708e-02, 4.16907368e-02,\n",
       "        3.33356879e-08, 6.48925546e-04, 2.16323613e-04, 5.17610343e-04,\n",
       "        6.36653302e-04, 2.72519249e-06, 4.23367580e-02, 1.41224598e-02,\n",
       "        3.39192626e-02, 4.17207444e-02, 1.23339338e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 1.93905980e-07, 3.93669247e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 4.27813651e-02, 3.09531334e-02, 9.58096470e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 4.81101616e-02, 4.67351523e-03, 1.66673373e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 3.53655597e-05,\n",
       "        2.08539701e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.22074038e-03, 3.52941176e-01, 4.21875670e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 4.63529181e-05, 3.48321752e-05, 6.28491620e-03,\n",
       "        0.00000000e+00, 6.12548113e-03, 1.10044882e-02, 3.58936484e-01,\n",
       "        0.00000000e+00, 1.66673373e-01, 3.65589251e-01, 2.09472096e-07,\n",
       "        3.90894067e-07, 6.02721939e-03, 2.23892454e-02, 4.17008375e-02,\n",
       "        2.50017660e-08, 4.89675412e-04, 1.63236530e-04, 3.81163583e-04,\n",
       "        4.72700055e-04, 2.51684444e-06, 4.21876161e-02, 1.40727099e-02,\n",
       "        3.39913201e-02, 4.17307266e-02, 1.70540193e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 1.94601869e-07, 3.95061026e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 4.59874627e-02, 3.16698708e-02, 1.00298072e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 5.17156070e-02, 6.12548113e-03, 1.66673373e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 4.63529181e-05,\n",
       "        2.08539701e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.22074038e-03, 3.52941176e-01, 9.74678841e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 6.68397633e-05, 3.48321752e-05, 9.06269398e-03,\n",
       "        0.00000000e+00, 8.83279254e-03, 1.58682002e-02, 3.58936484e-01,\n",
       "        0.00000000e+00, 1.66673373e-01, 3.65589251e-01, 1.02453033e-07,\n",
       "        1.66829523e-07, 1.39249654e-02, 3.43190753e-02, 5.57431961e-02,\n",
       "        3.33356879e-08, 5.57706303e-02, 1.85915076e-02, 4.57508254e-02,\n",
       "        5.57454875e-02, 2.15848579e-06, 9.74680110e-02, 3.25128360e-02,\n",
       "        4.11461743e-02, 5.57796693e-02, 2.90627175e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 8.25695974e-08, 1.70996483e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 5.19654989e-02, 3.36976999e-02, 1.13553498e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 5.84382603e-02, 8.83279254e-03, 1.66673373e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 6.68397633e-05,\n",
       "        2.08539701e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 3.11539114e-05, 0.00000000e+00,\n",
       "        3.11539114e-05, 3.11539114e-05, 5.57432040e-02, 0.00000000e+00,\n",
       "        5.57432040e-02, 5.57432040e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 9.95318925e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 4.45216917e-05, 2.37231481e-05, 6.03662322e-03,\n",
       "        0.00000000e+00, 5.88348681e-03, 1.05697430e-02, 2.44460857e-01,\n",
       "        0.00000000e+00, 1.13516227e-01, 2.48991856e-01, 6.77668379e-08,\n",
       "        1.63283542e-07, 1.42198445e-02, 3.51726230e-02, 5.77243944e-02,\n",
       "        3.33356879e-08, 5.77269236e-02, 1.92436509e-02, 4.73874301e-02,\n",
       "        5.77267108e-02, 1.77512538e-06, 9.95319726e-02, 3.32013208e-02,\n",
       "        4.23327043e-02, 5.77621636e-02, 4.19470500e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 8.07966072e-08, 1.67450502e-07, 0.00000000e+00,\n",
       "        1.02731223e-02, 3.51000896e-02, 2.28327003e-02, 5.21332203e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 3.94721154e-02, 5.88348681e-03, 1.13516227e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 4.45216917e-05,\n",
       "        2.08539701e-04, 2.37231481e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 4.58066969e-06, 0.00000000e+00,\n",
       "        4.58066969e-06, 4.58066969e-06, 5.77244023e-02, 0.00000000e+00,\n",
       "        5.77244023e-02, 5.77244023e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 9.48309675e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 6.82131831e-05, 2.37231481e-05, 9.24891372e-03,\n",
       "        0.00000000e+00, 9.01428828e-03, 1.61942591e-02, 2.44460857e-01,\n",
       "        0.00000000e+00, 1.13516227e-01, 2.48991856e-01, 8.51348206e-08,\n",
       "        1.71584335e-07, 1.35482364e-02, 3.32609092e-02, 5.31322784e-02,\n",
       "        3.33356879e-08, 5.31338781e-02, 1.77125289e-02, 4.36179551e-02,\n",
       "        5.31344197e-02, 8.41726121e-07, 9.48310736e-02, 3.16332211e-02,\n",
       "        3.97092607e-02, 5.31670436e-02, 3.15228328e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 8.49470035e-08, 1.75751295e-07, 0.00000000e+00,\n",
       "        1.02731223e-02, 4.20132376e-02, 2.62625984e-02, 6.89724077e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 4.72463570e-02, 9.01428828e-03, 1.13516227e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 6.82131831e-05,\n",
       "        2.08539701e-04, 2.37231481e-05, 4.10217285e-01, 3.37219238e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 3.42880538e-06, 0.00000000e+00,\n",
       "        3.42880538e-06, 3.42880538e-06, 5.31322862e-02, 0.00000000e+00,\n",
       "        5.31322862e-02, 5.31322862e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 5.68518338e-02, 4.43458980e-04,\n",
       "        1.56404776e-04, 6.10027292e-05, 3.48321752e-05, 8.27126009e-03,\n",
       "        0.00000000e+00, 6.44914853e-03, 1.29534970e-02, 3.58936484e-01,\n",
       "        0.00000000e+00, 2.22231164e-01, 4.22146105e-01, 1.69890370e-07,\n",
       "        2.88992702e-07, 8.12226261e-03, 2.96915752e-02, 5.54185482e-02,\n",
       "        2.50017660e-08, 5.68518895e-02, 1.42139644e-02, 3.90728438e-02,\n",
       "        5.54212729e-02, 2.43350522e-06, 5.54236868e-02, 2.77318869e-02,\n",
       "        5.56353628e-02, 5.54548090e-02, 8.96482678e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.19832130e-04,\n",
       "        2.71093131e-04, 1.80296145e-07, 2.19869746e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 5.02622596e-02, 3.30346487e-02, 1.09128802e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.65228675e-02, 6.44914853e-03, 2.22231164e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.43458980e-04, 6.10027292e-05,\n",
       "        1.56404776e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 9.62565678e-06, 0.00000000e+00,\n",
       "        9.62565678e-06, 9.62565678e-06, 5.54185561e-02, 0.00000000e+00,\n",
       "        5.54185561e-02, 5.54185561e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 1.55030718e-01, 6.65188470e-04,\n",
       "        2.08539701e-04, 2.82695574e-05, 3.48321752e-05, 3.83302297e-03,\n",
       "        0.00000000e+00, 2.13473558e-03, 5.07332581e-03, 3.58936484e-01,\n",
       "        0.00000000e+00, 1.66673373e-01, 3.65589251e-01, 5.04617988e-08,\n",
       "        1.43653200e-07, 1.55041649e-02, 2.90524147e-02, 5.37896081e-02,\n",
       "        2.50017660e-08, 1.13323620e-01, 1.88885883e-02, 3.03239908e-02,\n",
       "        5.37934413e-02, 7.80055098e-06, 9.55215080e-02, 3.18635323e-02,\n",
       "        4.00561663e-02, 5.38248033e-02, 2.45928132e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.24926801e-03,\n",
       "        3.54506402e-04, 9.11387309e-08, 1.07505571e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 3.05330703e-02, 2.67639979e-02, 7.16311585e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.32957417e-02, 2.13473558e-03, 1.66673373e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.65188470e-04, 2.82695574e-05,\n",
       "        2.08539701e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 6.37907186e-02, 0.00000000e+00,\n",
       "        6.37907186e-02, 6.37907186e-02, 5.37896160e-02, 0.00000000e+00,\n",
       "        5.37896160e-02, 5.37896160e-02],\n",
       "       [1.22074038e-03, 3.52941176e-01, 4.19133753e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 5.41356302e-05, 2.37231481e-05, 7.34016139e-03,\n",
       "        0.00000000e+00, 7.15395697e-03, 1.28521553e-02, 2.44460857e-01,\n",
       "        0.00000000e+00, 1.13516227e-01, 2.48991856e-01, 1.73788063e-07,\n",
       "        3.93478502e-07, 5.98804639e-03, 2.24102264e-02, 4.16968205e-02,\n",
       "        5.00035319e-08, 2.19500185e-04, 7.31718350e-05, 1.76530254e-04,\n",
       "        2.16523627e-04, 2.33349816e-07, 4.19133990e-02, 1.39812381e-02,\n",
       "        3.40976407e-02, 4.17267404e-02, 3.01885330e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 1.95894087e-07, 3.97645462e-07, 0.00000000e+00,\n",
       "        1.02731223e-02, 3.79054250e-02, 2.40709149e-02, 5.79408944e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 4.26268801e-02, 7.15395697e-03, 1.13516227e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 5.41356302e-05,\n",
       "        2.08539701e-04, 2.37231481e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00],\n",
       "       [1.22074038e-03, 3.52941176e-01, 4.19685920e-02, 3.32594235e-04,\n",
       "        2.08539701e-04, 5.24188555e-05, 3.48321752e-05, 7.10738672e-03,\n",
       "        0.00000000e+00, 6.92708730e-03, 1.24445817e-02, 3.58936484e-01,\n",
       "        0.00000000e+00, 1.66673373e-01, 3.65589251e-01, 2.18669572e-07,\n",
       "        3.92955334e-07, 5.99593504e-03, 2.24066246e-02, 4.16987707e-02,\n",
       "        5.83374539e-08, 2.72766896e-04, 9.09286448e-05, 2.09071557e-04,\n",
       "        2.60660078e-04, 2.34183208e-06, 4.19686074e-02, 1.39996542e-02,\n",
       "        3.40772791e-02, 4.17284917e-02, 1.22588794e-05, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.63673629e-04,\n",
       "        3.54506402e-04, 1.95632503e-07, 3.97122293e-07, 0.00000000e+00,\n",
       "        1.50837989e-02, 4.77574958e-02, 3.21807337e-02, 1.03559962e-03,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        7.93650794e-03, 5.37061133e-02, 6.92708730e-03, 1.66673373e-01,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.32594235e-04, 5.24188555e-05,\n",
       "        2.08539701e-04, 3.48321752e-05, 4.10217285e-01, 3.35693359e-03,\n",
       "        6.81198910e-04, 5.71428571e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haohao/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train, X_test, y_train, y_test are already defined and preprocessed.\n",
    "num_classes = len(np.unique(np.concatenate([y_train, y_test])))\n",
    "\n",
    "# Define and train models\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "cbt = CatBoostClassifier(verbose=0)\n",
    "cbt.fit(X_train, y_train)\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "bme = BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=10)\n",
    "bme.fit(X_train, y_train)\n",
    "\n",
    "# Deep Neural Network\n",
    "dnn = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "dnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn.fit(X_train, to_categorical(y_train, num_classes=num_classes), epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Predict probabilities\n",
    "prob_xgb = xgb.predict_proba(X_test)\n",
    "prob_cbt = cbt.predict_proba(X_test)\n",
    "prob_gbm = gbm.predict_proba(X_test)\n",
    "prob_bme = bme.predict_proba(X_test)\n",
    "prob_dnn = dnn.predict(X_test)  # This already gives probabilities due to softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, predictions):\n",
    "    acc = accuracy_score(y_true, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, predictions, average='weighted')\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - Accuracy: 0.9981, Precision: 0.9981, Recall: 0.9981, F1-Score: 0.9981\n",
      "CBT - Accuracy: 0.9987, Precision: 0.9987, Recall: 0.9987, F1-Score: 0.9987\n",
      "GBM - Accuracy: 0.9990, Precision: 0.9990, Recall: 0.9990, F1-Score: 0.9990\n",
      "BME - Accuracy: 0.9987, Precision: 0.9987, Recall: 0.9987, F1-Score: 0.9987\n",
      "DNN - Accuracy: 0.9935, Precision: 0.9940, Recall: 0.9935, F1-Score: 0.9936\n"
     ]
    }
   ],
   "source": [
    "# Convert predicted probabilities to class labels for evaluation\n",
    "predictions_xgb = np.argmax(prob_xgb, axis=1)\n",
    "predictions_cbt = np.argmax(prob_cbt, axis=1)\n",
    "predictions_gbm = np.argmax(prob_gbm, axis=1)\n",
    "predictions_bme = np.argmax(prob_bme, axis=1)\n",
    "predictions_dnn = np.argmax(prob_dnn, axis=1)\n",
    "\n",
    "# Evaluate each model\n",
    "results_xgb = evaluate_model(y_test, predictions_xgb)\n",
    "results_cbt = evaluate_model(y_test, predictions_cbt)\n",
    "results_gbm = evaluate_model(y_test, predictions_gbm)\n",
    "results_bme = evaluate_model(y_test, predictions_bme)\n",
    "results_dnn = evaluate_model(y_test, predictions_dnn)\n",
    "\n",
    "# Print results for each model\n",
    "print(\"XGB - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-Score: {:.4f}\".format(*results_xgb))\n",
    "print(\"CBT - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-Score: {:.4f}\".format(*results_cbt))\n",
    "print(\"GBM - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-Score: {:.4f}\".format(*results_gbm))\n",
    "print(\"BME - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-Score: {:.4f}\".format(*results_bme))\n",
    "print(\"DNN - Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1-Score: {:.4f}\".format(*results_dnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9989661792940482\n",
      "Ensemble Precision: 0.9989779465286168\n",
      "Ensemble Recall: 0.9989661792940482\n",
      "Ensemble F1-Score: 0.9989682491275246\n"
     ]
    }
   ],
   "source": [
    "# Ensemble learning\n",
    "\n",
    "# Weighted average of probabilities\n",
    "ensemble_probabilities = np.average(\n",
    "    [prob_xgb, prob_cbt, prob_gbm, prob_bme, prob_dnn],\n",
    "    axis=0,\n",
    "    weights=[0.3, 0.2, 0.2, 0.2, 0.1]\n",
    ")\n",
    "\n",
    "# Final prediction is the class with the highest average probability\n",
    "ensemble_predictions = np.argmax(ensemble_probabilities, axis=1)\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_results = evaluate_model(y_test, ensemble_predictions)\n",
    "\n",
    "print(\"Ensemble Accuracy:\", ensemble_results[0])\n",
    "print(\"Ensemble Precision:\", ensemble_results[1])\n",
    "print(\"Ensemble Recall:\", ensemble_results[2])\n",
    "print(\"Ensemble F1-Score:\", ensemble_results[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iD5e32NiAMKq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from imblearn.under_sampling import EditedNearestNeighbours\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "from tensorflow.keras import layers, Model\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/nsl_kdd_preprocessed.pkl', 'rb') as file:\n",
        "    X_train, X_test, y_train, y_test = pickle.load(file)"
      ],
      "metadata": {
        "id": "6YQy0NdEAPIo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Kích thước của tập huấn luyện (X_train):\", X_train.shape)\n",
        "print(\"Kích thước của tập kiểm tra (X_test):\", X_test.shape)\n",
        "print(\"Kích thước của tập huấn luyện (y_train):\", y_train.shape)\n",
        "print(\"Kích thước của tập kiểm tra (y_test):\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6Ub3GqgglS",
        "outputId": "c048dbee-7ba3-4828-cf36-4b7035658400"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kích thước của tập huấn luyện (X_train): (125972, 41)\n",
            "Kích thước của tập kiểm tra (X_test): (22543, 41)\n",
            "Kích thước của tập huấn luyện (y_train): (125972,)\n",
            "Kích thước của tập kiểm tra (y_test): (22543,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thống kê số mẫu mỗi lớp\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9BExe9nBCHa",
        "outputId": "e377ce76-92dd-4fda-ad23-4c2e3f032441"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "attack\n",
              "0    67342\n",
              "1    45927\n",
              "2    11656\n",
              "4      995\n",
              "3       52\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqzFj7-gg1Oy",
        "outputId": "9b38a8ac-0944-415d-a836-5275c519ebf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "attack\n",
              "0    9711\n",
              "1    7459\n",
              "4    2885\n",
              "2    2421\n",
              "3      67\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 20000 # Maximum number in a label\n",
        "# Lay danh sach cac class thuoc minority va majority\n",
        "Smin = []\n",
        "Smaj = []\n",
        "\n",
        "for label, cnt in y_train.value_counts().items():\n",
        "  if cnt >= (t * 0.7): # trainset:testset = 7:3\n",
        "    Smaj.append(label)\n",
        "  else:\n",
        "    Smin.append(label)\n",
        "\n",
        "print(Smin)\n",
        "print(Smaj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTEgjNYzg85o",
        "outputId": "96a76564-e1c4-4408-a53f-5a28531a2c00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 3]\n",
            "[0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Số lượng cụm và tổng số mẫu cần lấy từ mỗi lớp\n",
        "n_clusters = 5 # Num of classes\n",
        "samples_needed_per_class = int(t * 0.7) # t * 0.7\n",
        "\n",
        "# Khởi tạo một list để lưu các cụm và nhãn sau khi xử lý\n",
        "selected_samples_X = []\n",
        "selected_samples_y = []\n",
        "\n",
        "# Lọc ra các mẫu dữ liệu chỉ thuộc các nhãn trong Smaj\n",
        "majority_mask = np.isin(y_train, Smaj)\n",
        "X_majority = X_train[majority_mask]\n",
        "y_majority = y_train[majority_mask]\n",
        "\n",
        "print('ENN')\n",
        "# Áp dụng ENN để loại bỏ nhiễu\n",
        "enn = EditedNearestNeighbours()\n",
        "X_enn, y_enn = enn.fit_resample(X_majority, y_majority)\n",
        "\n",
        "# Duyệt qua từng nhãn trong nhãn đã làm sạch\n",
        "for label in Smaj:\n",
        "    print('Label: ', label)\n",
        "    label_mask = y_enn == label\n",
        "    X_label = X_enn[label_mask]\n",
        "\n",
        "    # Áp dụng k-means trên dữ liệu đã làm sạch cho mỗi nhãn\n",
        "    if len(X_label) > 1:  # Kiểm tra có đủ dữ liệu để phân cụm không\n",
        "        print('Clustering')\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "        kmeans.fit(X_label)\n",
        "        labels = kmeans.labels_\n",
        "\n",
        "        # Tính số mẫu cần lấy từ mỗi cụm\n",
        "        cluster_counts = np.bincount(labels, minlength=n_clusters)\n",
        "        cluster_ratios = cluster_counts / cluster_counts.sum()\n",
        "        samples_per_cluster = np.floor(cluster_ratios * samples_needed_per_class).astype(int)\n",
        "\n",
        "        # Đảm bảo rằng tổng số mẫu đúng bằng 16000, điều chỉnh nếu cần\n",
        "        while samples_per_cluster.sum() < samples_needed_per_class:\n",
        "            print('not enough')\n",
        "            samples_per_cluster[np.argmax(cluster_counts - samples_per_cluster)] += 1\n",
        "\n",
        "        print('Compressing')\n",
        "        # Lấy mẫu từ mỗi cụm\n",
        "        for cluster in range(n_clusters):\n",
        "            print('Cluster ', cluster)\n",
        "\n",
        "            cluster_mask = labels == cluster\n",
        "            X_cluster = X_label[cluster_mask]\n",
        "\n",
        "            if len(X_cluster) > 0:\n",
        "\n",
        "                # Chọn ngẫu nhiên các mẫu từ cụm\n",
        "                if len(X_cluster) > samples_per_cluster[cluster]:\n",
        "                    indices = np.random.choice(len(X_cluster), samples_per_cluster[cluster], replace=False)\n",
        "                    selected_samples_X.append(X_cluster.iloc[indices])\n",
        "                    selected_samples_y.extend([label] * samples_per_cluster[cluster])\n",
        "                else:\n",
        "                    selected_samples_X.append(X_cluster)\n",
        "                    selected_samples_y.extend([label] * len(X_cluster))\n",
        "\n",
        "# Tạo tập dữ liệu cuối cùng từ các mẫu đã chọn\n",
        "X_train_balanced = np.vstack(selected_samples_X)\n",
        "y_train_balanced = np.array(selected_samples_y)\n",
        "\n",
        "print(\"Số lượng mẫu cuối cùng được chọn: \", X_train_balanced.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STm8qDhIhR1D",
        "outputId": "36c7bcaa-0dae-407b-a82b-41f196538497"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENN\n",
            "Label:  0\n",
            "Clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not enough\n",
            "not enough\n",
            "not enough\n",
            "Compressing\n",
            "Cluster  0\n",
            "Cluster  1\n",
            "Cluster  2\n",
            "Cluster  3\n",
            "Cluster  4\n",
            "Label:  1\n",
            "Clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not enough\n",
            "not enough\n",
            "not enough\n",
            "Compressing\n",
            "Cluster  0\n",
            "Cluster  1\n",
            "Cluster  2\n",
            "Cluster  3\n",
            "Cluster  4\n",
            "Số lượng mẫu cuối cùng được chọn:  28000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values, counts = np.unique(y_train_balanced, return_counts=True)\n",
        "\n",
        "# Hiển thị các giá trị và tần suất xuất hiện tương ứng\n",
        "for value, count in zip(unique_values, counts):\n",
        "    print(f'{value}: {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGYZ39oejayZ",
        "outputId": "d75cfcb6-8f1f-49af-e73e-6e3138b070f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 14000\n",
            "1: 14000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo các hằng số\n",
        "BATCH_SIZE = 32\n",
        "LATENT_DIM = 128\n",
        "NUM_EPOCHS = 10\n",
        "SAMPLES_TO_GENERATE = int(t * 0.7)\n",
        "\n",
        "# Định nghĩa mô hình Generator\n",
        "def build_generator():\n",
        "    noise = layers.Input(shape=(LATENT_DIM,))\n",
        "    x = layers.Dense(256, activation=\"relu\")(noise)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(np.prod(X_train.shape[1:]), activation=None)(x)\n",
        "    samp = layers.Reshape(X_train.shape[1:])(x)\n",
        "    return Model(noise, samp)\n",
        "\n",
        "# Định nghĩa mô hình Discriminator\n",
        "def build_discriminator():\n",
        "    samp = layers.Input(shape=X_train.shape[1:])\n",
        "    x = layers.Flatten()(samp)\n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "    return Model(samp, x)\n",
        "\n",
        "\n",
        "# Hàm để sinh dữ liệu\n",
        "def generate_data_for_class(label):\n",
        "    global X_train_balanced, y_train_balanced, X_train, y_train\n",
        "    current_data = X_train[y_train == label]\n",
        "    current_samples = current_data.shape[0]\n",
        "    samples_needed = SAMPLES_TO_GENERATE - current_samples\n",
        "\n",
        "    X_train_balanced = np.concatenate([X_train_balanced, current_data], axis=0)\n",
        "    y_train_balanced = np.concatenate([y_train_balanced, np.full(current_samples, label)], axis=0)\n",
        "\n",
        "    if samples_needed > 0:\n",
        "        noise = np.random.normal(0, 1, (samples_needed, LATENT_DIM))\n",
        "        generated_samples = generator.predict(noise)\n",
        "\n",
        "        # Gộp dữ liệu sinh ra vào X_train và y_train\n",
        "        X_train_balanced = np.concatenate([X_train_balanced, generated_samples], axis=0)\n",
        "        y_train_balanced = np.concatenate([y_train_balanced, np.full(samples_needed, label)], axis=0)\n",
        "\n",
        "# Huấn luyện WGAN cho mỗi class thiểu số\n",
        "for label in Smin:\n",
        "\n",
        "    # Tối ưu hoá và loss function\n",
        "    optimizer = legacy.RMSprop(lr=0.00005)\n",
        "\n",
        "    generator = build_generator()\n",
        "    discriminator = build_discriminator()\n",
        "\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    noise = layers.Input(shape=(LATENT_DIM,))\n",
        "    samp = generator(noise)\n",
        "    validity = discriminator(samp)\n",
        "    combined = Model(noise, validity)\n",
        "    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    data = X_train[y_train == label]\n",
        "    valid = np.ones((BATCH_SIZE, 1))\n",
        "    fake = -np.ones((BATCH_SIZE, 1))\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        idx = np.random.randint(0, data.shape[0], BATCH_SIZE)\n",
        "        real_samp = data.iloc[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
        "        gen_samp = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_samp, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_samp, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "    generate_data_for_class(label)  # Sinh dữ liệu cho class hiện tại"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YkTLZBYjrzA",
        "outputId": "6fb8f0fc-203d-445a-898f-a3ccf6353160"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/rmsprop.py:144: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 390ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "74/74 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/rmsprop.py:144: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "407/407 [==============================] - 2s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/rmsprop.py:144: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "436/436 [==============================] - 2s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values, counts = np.unique(y_train_balanced, return_counts=True)\n",
        "\n",
        "# Hiển thị các giá trị và tần suất xuất hiện tương ứng\n",
        "for value, count in zip(unique_values, counts):\n",
        "    print(f'{value}: {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t87p0kRWj7UU",
        "outputId": "6a9486bf-8628-414e-ba81-bfef3c30d095"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 14000\n",
            "1: 14000\n",
            "2: 14000\n",
            "3: 14000\n",
            "4: 14000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Giam du lieu X_test, y_test bang cach chon ngau nhien\n",
        "\n",
        "def reduce_data(X_test, y_test, n):\n",
        "    unique_classes = np.unique(y_test)\n",
        "    X_test_reduced = np.empty((0, X_test.shape[1]))\n",
        "    y_test_reduced = np.array([])\n",
        "\n",
        "    for label in unique_classes:\n",
        "        indices = np.where(y_test == label)[0]\n",
        "        if len(indices) > n:\n",
        "            indices = np.random.choice(indices, n, replace=False)\n",
        "        X_subset = X_test.iloc[indices]\n",
        "        y_subset = y_test.iloc[indices]\n",
        "\n",
        "        X_test_reduced = np.vstack((X_test_reduced, X_subset))\n",
        "        y_test_reduced = np.concatenate((y_test_reduced, y_subset))\n",
        "\n",
        "    return X_test_reduced, y_test_reduced\n",
        "\n",
        "X_test_reduced, y_test_reduced = reduce_data(X_test, y_test, int(t * 0.3))"
      ],
      "metadata": {
        "id": "Q40chtMWk_Bp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_reduced = y_test_reduced.astype('int64')\n",
        "unique_values, counts = np.unique(y_test_reduced, return_counts=True)\n",
        "\n",
        "# Hiển thị các giá trị và tần suất xuất hiện tương ứng\n",
        "for value, count in zip(unique_values, counts):\n",
        "    print(f'{value}: {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MGeMq2RlIsB",
        "outputId": "f7004cc3-8ef9-484b-c0fc-ef4ed71eeec5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 6000\n",
            "1: 6000\n",
            "2: 2421\n",
            "3: 67\n",
            "4: 2885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu dữ liệu vào file\n",
        "data = {\n",
        "    'X_train': X_train_balanced,\n",
        "    'X_test': X_test_reduced,\n",
        "    'y_train': y_train_balanced,\n",
        "    'y_test': y_test_reduced\n",
        "}\n",
        "\n",
        "with open('nsl-kdd-balanced.pkl', 'wb') as file:\n",
        "    pickle.dump(data, file)"
      ],
      "metadata": {
        "id": "7IQoxS9glN1Y"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}